---
type: past
date: 2018-09-16T8:00:00+1:00
speaker: Matthew Jagielski
affiliation: Google Research
title: "Evaluating Heuristic Defenses in Machine Learning Privacy"
bio: "Matthew is a research scientist at Google, Cambridge, working in the intersection between machine learning, security, and privacy. He received his PhD from Northeastern University, where he was advised by Cristina Nita-Rotaru and Alina Oprea.
"
abstract: "In this talk, I will discuss four recent papers which evaluate potential heuristic defenses for membership inference and training data extraction. Starting with training data extraction, I will talk about the pitfalls in attempting to ``censor'' memorized training data, with some analysis on Github Copilot. Next, I will talk about membership inference defenses. I will discuss what happens after removing vulnerable examples from a training set. Next, I'll talk about how membership inference and extraction appear to have a ``recency bias'': recently seen examples tend to be more vulnerable. Finally, I will discuss the possibility of using model distillation as a defense for membership inference."
youtube: w83umqumcoc
---
