---
type: past
date: 2025-11-26T15:00:00+1:00
speaker: Christian Wressnegger
affiliation: KIT
title: "Explanation-Aware Attacks and the Limits of using XAI in Computer Security"
bio: "Christian Wressnegger is a professor of computer science at the Karlsruhe Institute of Technology (KIT), heading the chair of "Artificial Intelligence & Security." Additionally, he serves as the spokesperson for the "KIT Graduate School Cyber Security," is co-director of the "KASTEL Security Research Labs," one of three competence centers for cybersecurity in Germany, and has been appointed Junior Fellow of the Berlin Institute for the Foundations of Learning and Data (BIFOLD). He holds a Ph.D. from TU Braunschweig and has graduated from Graz University of Technology, where he majored in computer science.
His research revolves around combining machine learning (or AI in the broader scope) and computer security. He develop methods in the area of system security but also research the robustness of machine learning against attacks striving for "secure AI." He is particularly visible for his work on the security of XAI."
abstract: "Learning-based systems effectively assist in various computer security challenges, such as preventing network intrusions, reverse engineering, vulnerability discovery, or detecting malware. However, modern (deep) learning methods often lack understandable reasoning in their decision process, making crucial decisions less trustworthy. Recent advances in "Explainable AI" (XAI) have turned the tables, enabling precise relevance attribution of input features for otherwise opaque models. This progression has raised expectations that these techniques can also benefit defense against attacks on computer systems and even machine learning models themselves. This talk disucsses explanation-aware attacks against neural networks and explores limits of XAI in computer security, demonstrating where it can and cannot (yet) be used reliably."
youtube: YX03rneh8iw
---
